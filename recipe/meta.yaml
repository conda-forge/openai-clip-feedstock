{% set name = "openai-clip" %}
{% set version = "1.0.1" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/openai-clip-{{ version }}.tar.gz
  sha256: cd40bf2f205c096c49524fcbff484339f793b52afd6e7ffad80a2fe108151721

build:
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv
  number: 0

requirements:
  host:
    - python >=3.8
    - pip
  run:
    - python >=3.8
    - ftfy
    - regex
    - tqdm
    - pytorch >=1.7
    - torchvision >=0.8

test:
  imports:
    - clip
  commands:
    - pip check
  requires:
    - pip

about:
  home: https://pypi.org/project/openai-clip
  summary: CLIP (Contrastive Language-Image Pretraining), Predict the most relevant text snippet given an image
  license: MIT
  license_family: MIT
  license_file: LICENSE
  dev_url: https://github.com/openai/CLIP

extra:
  recipe-maintainers:
    - giswqs
